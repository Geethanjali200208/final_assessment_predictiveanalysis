# -*- coding: utf-8 -*-
"""LVADSUSR87-geethanjaliLab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10BJM1BPtu_H4-U2Z_1D7pMPTMPQYJOPW
"""

#1 random forest-classification
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report
#dataset
data=pd.read_csv("/content/loan_approval.csv")
#Handling missing values (forward fill) and removing duplicates
data = data.fillna(method='ffill')
data = data.drop_duplicates()

#Outlier detection using IQR method
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)
data = data[~outliers]

#EDA
a=data.describe()
b=data.shape
c=data.info()

#Encoding categorical variables
label_encoder = LabelEncoder()
data[' education'] = label_encoder.fit_transform(data[' education'])
data[' self_employed'] = label_encoder.fit_transform(data[' self_employed'])
#print(data)
#features and labels
x = data.drop([' loan_status', 'loan_id'], axis=1)
y = data[' loan_status']

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Model training
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train_scaled, y_train)

# Model testing
y_pred = clf.predict(X_test_scaled)
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()